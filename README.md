
# <center>Wikipedia_webCrawler_game</center>

### <center> A simple Wikipedia web Crawler game</center> 
---
#### <center> what is this?</center>
This software is a simple Wikipedia web crawler. It asks the user for two inputs: The starting page, and the ending page. Once verified the existence (or availability) of the two Wikipedia pages, the game will start. The software will end only in two scenarios: It reached the destination(ending page), or it came to a dead-end. At the end of the game, the software will produce the number of pages visited.

---

#### <center> How is made? </center>
The software is entirely written in python 3. The main libraries used in the software are Beautifulsoup4, requests, and random. Beautifulsoup is used for the data retrieval of the pages, requests to make a connection between user and server, and random to generate the movement. The software will retrieve the HTML of the current page and will produce a list of valid Wikipedia links. The list is later used to choose a random new link and repeat the process recursively until a stop criterion is met. Future updates might include new libraries and functionalities

---
#### <center> Why this? </center>
Web Crawling is a relatively easy operation that can be achieved by the most. My intent with this is to keep expanding this project and meanwhile achieve new knowledge with future updates. Web crawlers have the incredible characteristic of being capable of concatenation with more complex computational concepts such as Deep Learning, multi-threading, GUI, and much more.


# <center> HOW TO SET IT UP </center>
:warning:  you MUST have BeautifulSoup4 intalled in order to run the code :warning:
<center> To install execute the following code in Python Terminal
</center>

```python
pip install beautifulsoup4
```

1. Clone the GitHub repo:
``````
2. 
3. 




